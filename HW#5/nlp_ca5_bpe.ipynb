{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpY83FTzajEw"
      },
      "outputs": [],
      "source": [
        "!pip install fairseq\n",
        "!pip install sentencepiece\n",
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentencepiece import SentencePieceTrainer\n",
        "\n",
        "# Train Farsi model\n",
        "trainer = SentencePieceTrainer.train(\n",
        "    input=\"/content/drive/MyDrive/datasets/nlp/ca5/train.fa\",\n",
        "    model_prefix=\"/content/fa.model\",\n",
        "    vocab_size=10000,\n",
        "    model_type=\"bpe\",\n",
        ")\n",
        "\n",
        "# Train English model\n",
        "trainer = SentencePieceTrainer.train(\n",
        "    input=\"/content/drive/MyDrive/datasets/nlp/ca5/train.en\",\n",
        "    model_prefix=\"/content/en.model\",\n",
        "    vocab_size=10000,\n",
        "    model_type=\"bpe\",\n",
        ")\n",
        "\n",
        "print(\"BPE models trained successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3BOvKz0b0K7",
        "outputId": "73406124-99f3-4c4a-f5db-361702565e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BPE models trained successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head /content/en.model.vocab -n 10"
      ],
      "metadata": {
        "id": "X4q84-xgi9P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "# Load English tokenizer\n",
        "sp_en = spm.SentencePieceProcessor()\n",
        "sp_en.load('/content/en.model.model')\n",
        "\n",
        "# Load Persian tokenizer\n",
        "sp_fa = spm.SentencePieceProcessor()\n",
        "sp_fa.load('/content/fa.model.model')\n",
        "\n",
        "def tokenize_data(sp, input_path, output_path):\n",
        "    with open(input_path, 'r', encoding='utf-8') as fin, open(output_path, 'w', encoding='utf-8') as fout:\n",
        "        for line in fin:\n",
        "            tokens = sp.encode(line.strip(), out_type=str)\n",
        "            fout.write(' '.join(tokens) + '\\n')\n",
        "\n",
        "# Tokenize English datasets\n",
        "tokenize_data(sp_en, '/content/drive/MyDrive/datasets/nlp/ca5/train.en', '/content/drive/MyDrive/datasets/nlp/ca5/train.tok.en')\n",
        "tokenize_data(sp_en, '/content/drive/MyDrive/datasets/nlp/ca5/eval.en', '/content/drive/MyDrive/datasets/nlp/ca5/eval.tok.en')\n",
        "tokenize_data(sp_en, '/content/drive/MyDrive/datasets/nlp/ca5/test.en', '/content/drive/MyDrive/datasets/nlp/ca5/test.tok.en')\n",
        "\n",
        "# Tokenize Persian datasets\n",
        "tokenize_data(sp_fa, '/content/drive/MyDrive/datasets/nlp/ca5/train.fa', '/content/drive/MyDrive/datasets/nlp/ca5/train.tok.fa')\n",
        "tokenize_data(sp_fa, '/content/drive/MyDrive/datasets/nlp/ca5/eval.fa', '/content/drive/MyDrive/datasets/nlp/ca5/eval.tok.fa')\n",
        "tokenize_data(sp_fa, '/content/drive/MyDrive/datasets/nlp/ca5/test.fa', '/content/drive/MyDrive/datasets/nlp/ca5/test.tok.fa')\n"
      ],
      "metadata": {
        "id": "txlNi-CDhr7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-preprocess --source-lang en --target-lang fa \\\n",
        "  --trainpref '/content/drive/MyDrive/datasets/nlp/ca5/train.tok' \\\n",
        "  --validpref '/content/drive/MyDrive/datasets/nlp/ca5/eval.tok' \\\n",
        "  --testpref '/content/drive/MyDrive/datasets/nlp/ca5/test.tok' \\\n",
        "  --destdir '/content/drive/MyDrive/datasets/nlp/ca5/data-bin' \\\n",
        "  --source-lang en --target-lang fa \\\n",
        "  --nwordssrc 10000 --nwordstgt 10000 \\\n",
        "  --workers 20"
      ],
      "metadata": {
        "id": "cY_MV7KvU3D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv '/content/en.model.model' '/content/drive/MyDrive/datasets/nlp/ca5/en.model.model'\n",
        "!mv '/content/en.model.vocab' '/content/drive/MyDrive/datasets/nlp/ca5/en.model.vocab'\n",
        "!mv '/content/fa.model.model' '/content/drive/MyDrive/datasets/nlp/ca5/fa.model.model'\n",
        "!mv '/content/fa.model.vocab' '/content/drive/MyDrive/datasets/nlp/ca5/fa.model.vocab'"
      ],
      "metadata": {
        "id": "MDlAd9mraKqB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}