{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_uUQKoq63XN"
      },
      "outputs": [],
      "source": [
        "!pip install contractions\n",
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qrk_jUP7ENt"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/kazanova/sentiment140?resource=download\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preprocessing"
      ],
      "metadata": {
        "id": "VqiERp8nGKEM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wwD_7TWH7RhM"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as stopwords\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L35LplgZ7Vu8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/sentiment140/training.1600000.processed.noemoticon.csv',header=None ,encoding='latin-1')\n",
        "df.columns = ['target','ids','date','flag','user','text']\n",
        "\n",
        "df_type1 = df[df['target'] == 0]\n",
        "df_type2 = df[df['target'] == 4]\n",
        "\n",
        "df_type1_sample = df_type1.sample(n=5000, random_state=42)\n",
        "df_type2_sample = df_type2.sample(n=5000, random_state=42)\n",
        "\n",
        "final_df = pd.concat([df_type1_sample, df_type2_sample])\n",
        "final_df = final_df.sample(frac=1, random_state=42)\n",
        "\n",
        "final_df['target'] = final_df['target'].replace(4, 1)\n",
        "\n",
        "df = final_df.copy()\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Lowercasing\n",
        "df['text'] = df['text'].str.lower()\n",
        "\n",
        "# Tokenization\n",
        "df['text'] = df['text'].apply(word_tokenize)\n",
        "\n",
        "# Stemming (Using Porter Stemmer from NLTK)\n",
        "stemmer = nltk.PorterStemmer()\n",
        "df['text'] = df['text'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
        "\n",
        "# Removing Numbers\n",
        "df['text'] = df['text'].apply(lambda tokens: [token for token in tokens if not token.isdigit()])\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_df['text'], test_df['text'],train_df['target'], test_df['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYMHq_lAXXzp"
      },
      "source": [
        "### Term Frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUCqYvctsNVa"
      },
      "outputs": [],
      "source": [
        "class CustomTF:\n",
        "    def __init__(self, documents):\n",
        "        self.documents = documents\n",
        "        self.vocab = set()\n",
        "        self.term_freq_matrix = None\n",
        "        self.epsilon = 1e-8  # Small constant for unseen words\n",
        "        self.smoothing = 1\n",
        "\n",
        "    def _calculate_tf(self, document):\n",
        "        term_freqs = Counter(document)\n",
        "        total_words = len(document)\n",
        "        unique_words = len(set(document))\n",
        "        tf = {term: (freq + self.smoothing) / (total_words + unique_words) for term, freq in term_freqs.items()}\n",
        "        return tf\n",
        "\n",
        "    def fit_transform(self):\n",
        "        for doc in self.documents:\n",
        "            self.vocab.update(doc)\n",
        "\n",
        "        self.vocab = list(self.vocab)\n",
        "        self.term_freq_matrix = []\n",
        "\n",
        "        for doc in self.documents:\n",
        "            tf = self._calculate_tf(doc)\n",
        "            doc_vector = [tf[word] if word in tf else 0 for word in self.vocab]\n",
        "            self.term_freq_matrix.append(doc_vector)\n",
        "\n",
        "        return np.array(self.term_freq_matrix)\n",
        "\n",
        "    def transform(self, documents):\n",
        "        term_freq_matrix = []\n",
        "        for doc in documents:\n",
        "            tf = self._calculate_tf(doc)\n",
        "            doc_vector = [tf.get(word, self.epsilon) for word in self.vocab]\n",
        "            term_freq_matrix.append(doc_vector)\n",
        "        return np.array(term_freq_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v1S0qTzB-B2",
        "outputId": "382d7dbe-b1ea-4e6d-a03d-71d836e2b89d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using term frequencies for MultinomialNB: 0.7585\n",
            "Precision using term frequencies for MultinomialNB: 0.7680851063829788\n",
            "Recall using term frequencies for MultinomialNB: 0.7315096251266464\n",
            "F1-score using term frequencies for MultinomialNB: 0.7493513233004672\n",
            "Accuracy using term frequencies for GaussianNB: 0.5585\n",
            "Precision using term frequencies for GaussianNB: 0.6256038647342995\n",
            "Recall using term frequencies for GaussianNB: 0.2624113475177305\n",
            "F1-score using term frequencies for GaussianNB: 0.3697359029264811\n"
          ]
        }
      ],
      "source": [
        "custom_tf = CustomTF(X_train)\n",
        "X_train_tf = custom_tf.fit_transform()\n",
        "\n",
        "\n",
        "X_test_tf = custom_tf.transform(X_test)\n",
        "\n",
        "\n",
        "naive_bayes_tf = MultinomialNB()\n",
        "naive_bayes_tf.fit(X_train_tf, y_train)\n",
        "\n",
        "\n",
        "y_pred_tf = naive_bayes_tf.predict(X_test_tf)\n",
        "\n",
        "\n",
        "accuracy_tf = accuracy_score(y_test, y_pred_tf)\n",
        "print(\"Accuracy using term frequencies for MultinomialNB:\", accuracy_tf)\n",
        "\n",
        "\n",
        "precision_tf = precision_score(y_test, y_pred_tf)\n",
        "recall_tf = recall_score(y_test, y_pred_tf)\n",
        "f1_tf = f1_score(y_test, y_pred_tf)\n",
        "\n",
        "print(\"Precision using term frequencies for MultinomialNB:\", precision_tf)\n",
        "print(\"Recall using term frequencies for MultinomialNB:\", recall_tf)\n",
        "print(\"F1-score using term frequencies for MultinomialNB:\", f1_tf)\n",
        "\n",
        "\n",
        "naive_bayes_gaussian = GaussianNB()\n",
        "naive_bayes_gaussian.fit(X_train_tf, y_train)\n",
        "\n",
        "\n",
        "y_pred_gaussian = naive_bayes_gaussian.predict(X_test_tf)\n",
        "\n",
        "\n",
        "accuracy_gaussian = accuracy_score(y_test, y_pred_gaussian)\n",
        "print(\"Accuracy using term frequencies for GaussianNB:\", accuracy_gaussian)\n",
        "\n",
        "\n",
        "precision_gaussian = precision_score(y_test, y_pred_gaussian)\n",
        "recall_gaussian = recall_score(y_test, y_pred_gaussian)\n",
        "f1_gaussian = f1_score(y_test, y_pred_gaussian)\n",
        "\n",
        "print(\"Precision using term frequencies for GaussianNB:\", precision_gaussian)\n",
        "print(\"Recall using term frequencies for GaussianNB:\", recall_gaussian)\n",
        "print(\"F1-score using term frequencies for GaussianNB:\", f1_gaussian)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gZUSs1jMdfn"
      },
      "source": [
        "### TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COnfCU4LmRMa"
      },
      "outputs": [],
      "source": [
        "class CustomTFIDF:\n",
        "    def __init__(self, documents, smoothing=1):\n",
        "        self.documents = documents\n",
        "        self.vocab = set()\n",
        "        self.idf = None\n",
        "        self.smoothing = smoothing\n",
        "        self.epsilon = 1e-3  # Small constant for unseen words\n",
        "\n",
        "    def _calculate_tf(self, document):\n",
        "        term_freqs = Counter(document)\n",
        "        total_words = len(document)\n",
        "        tf = {term: freq/total_words for term, freq in term_freqs.items()}\n",
        "        return tf\n",
        "\n",
        "    def _calculate_idf(self):\n",
        "        num_documents = len(self.documents)\n",
        "        idf = {}\n",
        "        for word in self.vocab:\n",
        "            doc_count = sum([1 for doc in self.documents if word in doc])\n",
        "            idf[word] = np.log((num_documents + self.smoothing) / (doc_count + self.smoothing))  # Additive smoothing\n",
        "        return idf\n",
        "\n",
        "    def fit(self):\n",
        "        for doc in self.documents:\n",
        "            self.vocab.update(doc)\n",
        "        self.vocab = list(self.vocab)\n",
        "        self.idf = self._calculate_idf()\n",
        "\n",
        "    def transform(self, documents):\n",
        "        doc_term_matrix = []\n",
        "        for doc in documents:\n",
        "            tf = self._calculate_tf(doc)\n",
        "            doc_vector = [(tf.get(word, self.epsilon) * self.idf.get(word, np.finfo(float).eps)) for word in self.vocab]\n",
        "            doc_term_matrix.append(doc_vector)\n",
        "        return np.array(doc_term_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV0SO1kDPfnP",
        "outputId": "76966f04-8325-4274-f6d6-90a89f24be93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy (MultinomialNB): 0.751\n",
            "Precision (MultinomialNB): 0.7472194135490394\n",
            "Recall (MultinomialNB): 0.7487335359675785\n",
            "F1-score (MultinomialNB): 0.7479757085020242\n",
            "Accuracy (GaussianNB): 0.555\n",
            "Precision (GaussianNB): 0.6125290023201856\n",
            "Recall (GaussianNB): 0.2674772036474164\n",
            "F1-score (GaussianNB): 0.3723554301833569\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "custom_tfidf = CustomTFIDF(X_train, smoothing=1)\n",
        "custom_tfidf.fit()\n",
        "\n",
        "\n",
        "X_train_tfidf = custom_tfidf.transform(X_train)\n",
        "X_test_tfidf = custom_tfidf.transform(X_test)\n",
        "\n",
        "\n",
        "naive_bayes_multinomial = MultinomialNB()\n",
        "naive_bayes_multinomial.fit(X_train_tfidf, y_train)\n",
        "\n",
        "\n",
        "y_pred_multinomial = naive_bayes_multinomial.predict(X_test_tfidf)\n",
        "\n",
        "\n",
        "accuracy_multinomial = accuracy_score(y_test, y_pred_multinomial)\n",
        "print(\"Accuracy (MultinomialNB):\", accuracy_multinomial)\n",
        "\n",
        "\n",
        "precision_multinomial = precision_score(y_test, y_pred_multinomial)\n",
        "recall_multinomial = recall_score(y_test, y_pred_multinomial)\n",
        "f1_multinomial = f1_score(y_test, y_pred_multinomial)\n",
        "\n",
        "print(\"Precision (MultinomialNB):\", precision_multinomial)\n",
        "print(\"Recall (MultinomialNB):\", recall_multinomial)\n",
        "print(\"F1-score (MultinomialNB):\", f1_multinomial)\n",
        "\n",
        "\n",
        "naive_bayes_gaussian = GaussianNB()\n",
        "naive_bayes_gaussian.fit(X_train_tfidf, y_train)\n",
        "\n",
        "\n",
        "y_pred_gaussian = naive_bayes_gaussian.predict(X_test_tfidf)\n",
        "\n",
        "\n",
        "accuracy_gaussian = accuracy_score(y_test, y_pred_gaussian)\n",
        "print(\"Accuracy (GaussianNB):\", accuracy_gaussian)\n",
        "\n",
        "\n",
        "precision_gaussian = precision_score(y_test, y_pred_gaussian)\n",
        "recall_gaussian = recall_score(y_test, y_pred_gaussian)\n",
        "f1_gaussian = f1_score(y_test, y_pred_gaussian)\n",
        "\n",
        "print(\"Precision (GaussianNB):\", precision_gaussian)\n",
        "print(\"Recall (GaussianNB):\", recall_gaussian)\n",
        "print(\"F1-score (GaussianNB):\", f1_gaussian)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhiDC8ABQZxn"
      },
      "source": [
        "### PPMI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomPPMI:\n",
        "    def __init__(self):\n",
        "        self.vocab = set()\n",
        "        self.word_to_index = {}\n",
        "        self.index_to_word = {}\n",
        "        self.co_occurrence_matrix = None\n",
        "        self.ppmi_matrix = None\n",
        "\n",
        "    def _build_co_occurrence_matrix(self, documents, window_size=2):\n",
        "        word_count = len(self.vocab)\n",
        "        self.co_occurrence_matrix = np.zeros((word_count, word_count))\n",
        "\n",
        "        for doc in documents:\n",
        "            for i, word in enumerate(doc):\n",
        "                if word in self.vocab:\n",
        "                    current_index = self.word_to_index[word]\n",
        "                    start = max(0, i - window_size)\n",
        "                    end = min(len(doc), i + window_size + 1)\n",
        "                    context = doc[start:end]\n",
        "                    context.remove(word)\n",
        "                    for context_word in context:\n",
        "                        if context_word in self.vocab:\n",
        "                            context_index = self.word_to_index[context_word]\n",
        "                            self.co_occurrence_matrix[current_index][context_index] += 1\n",
        "\n",
        "    def _calculate_ppmi(self):\n",
        "        total_occurrences = np.sum(self.co_occurrence_matrix)\n",
        "        word_count = len(self.vocab)\n",
        "        self.ppmi_matrix = np.zeros((word_count, word_count))\n",
        "\n",
        "        for i in range(word_count):\n",
        "            for j in range(word_count):\n",
        "                if self.co_occurrence_matrix[i][j] == 0:\n",
        "                    self.ppmi_matrix[i][j] = 0\n",
        "                else:\n",
        "                    word_i_freq = np.sum(self.co_occurrence_matrix[i])\n",
        "                    word_j_freq = np.sum(self.co_occurrence_matrix[j])\n",
        "                    joint_freq = self.co_occurrence_matrix[i][j]\n",
        "                    pmi = np.log2((joint_freq * total_occurrences) / (word_i_freq * word_j_freq))\n",
        "                    self.ppmi_matrix[i][j] = max(pmi, 0)\n",
        "\n",
        "    def fit(self, documents, window_size=2):\n",
        "        for doc in documents:\n",
        "            self.vocab.update(doc)\n",
        "\n",
        "        self.vocab = list(self.vocab)\n",
        "\n",
        "        for i, word in enumerate(self.vocab):\n",
        "            self.word_to_index[word] = i\n",
        "            self.index_to_word[i] = word\n",
        "\n",
        "        self._build_co_occurrence_matrix(documents, window_size)\n",
        "        self._calculate_ppmi()\n",
        "\n",
        "    def transform(self, documents):\n",
        "        ppmi_vectors = []\n",
        "        for doc in documents:\n",
        "            ppmi_vector = np.zeros((len(self.vocab),))  # Initialize PPMI vector\n",
        "            for word in doc:\n",
        "                if word in self.vocab:\n",
        "                    word_index = self.word_to_index[word]\n",
        "                    ppmi_vector += self.ppmi_matrix[word_index]  # Accumulate PPMI values\n",
        "            ppmi_vectors.append(ppmi_vector)\n",
        "        return np.array(ppmi_vectors)\n",
        "\n"
      ],
      "metadata": {
        "id": "YGA16p97mcaX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_ppmi = CustomPPMI()\n",
        "custom_ppmi.fit(X_train)\n",
        "\n",
        "\n",
        "X_train_ppmi = custom_ppmi.transform(X_train)\n",
        "X_test_ppmi = custom_ppmi.transform(X_test)\n",
        "\n",
        "\n",
        "naive_bayes_multinomial = MultinomialNB()\n",
        "naive_bayes_multinomial.fit(X_train_ppmi, y_train)\n",
        "\n",
        "\n",
        "y_pred_multinomial = naive_bayes_multinomial.predict(X_test_ppmi)\n",
        "\n",
        "\n",
        "accuracy_multinomial = accuracy_score(y_test, y_pred_multinomial)\n",
        "print(\"Accuracy (MultinomialNB):\", accuracy_multinomial)\n",
        "\n",
        "\n",
        "precision_multinomial = precision_score(y_test, y_pred_multinomial)\n",
        "recall_multinomial = recall_score(y_test, y_pred_multinomial)\n",
        "f1_multinomial = f1_score(y_test, y_pred_multinomial)\n",
        "\n",
        "print(\"Precision (MultinomialNB):\", precision_multinomial)\n",
        "print(\"Recall (MultinomialNB):\", recall_multinomial)\n",
        "print(\"F1-score (MultinomialNB):\", f1_multinomial)\n",
        "\n",
        "\n",
        "naive_bayes_gaussian = GaussianNB()\n",
        "naive_bayes_gaussian.fit(X_train_ppmi, y_train)\n",
        "\n",
        "\n",
        "y_pred_gaussian = naive_bayes_gaussian.predict(X_test_ppmi)\n",
        "\n",
        "\n",
        "accuracy_gaussian = accuracy_score(y_test, y_pred_gaussian)\n",
        "print(\"Accuracy (GaussianNB):\", accuracy_gaussian)\n",
        "\n",
        "\n",
        "precision_gaussian = precision_score(y_test, y_pred_gaussian)\n",
        "recall_gaussian = recall_score(y_test, y_pred_gaussian)\n",
        "f1_gaussian = f1_score(y_test, y_pred_gaussian)\n",
        "\n",
        "print(\"Precision (GaussianNB):\", precision_gaussian)\n",
        "print(\"Recall (GaussianNB):\", recall_gaussian)\n",
        "print(\"F1-score (GaussianNB):\", f1_gaussian)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtsYCcvBiLYI",
        "outputId": "a4120354-647c-4f23-cf28-bcd0487ff3f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (MultinomialNB): 0.639\n",
            "Precision (MultinomialNB): 0.6417112299465241\n",
            "Recall (MultinomialNB): 0.60790273556231\n",
            "F1-score (MultinomialNB): 0.6243496357960457\n",
            "Accuracy (GaussianNB): 0.653\n",
            "Precision (GaussianNB): 0.6890322580645162\n",
            "Recall (GaussianNB): 0.541033434650456\n",
            "F1-score (GaussianNB): 0.6061293984108966\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}