{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T13:54:28.165995Z","iopub.status.busy":"2024-05-24T13:54:28.165587Z"},"trusted":true},"outputs":[],"source":["from transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer, default_data_collator\n","from datasets import load_dataset\n","\n","# Load tokenizer and model\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")\n","model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\", num_labels=3)  # 3 for entailment, neutral, contradiction\n","\n","# Download and load MultiNLI dataset\n","train_data = load_dataset(\"glue\", name=\"mnli\", split=\"train\")\n","# Sample 10% of the data for training\n","train_data = train_data.select(range(len(train_data) // 30))  # Select first 3% of the data\n","\n","dev_data = load_dataset(\"glue\", name=\"mnli\", split=\"validation_matched\")  # Use matched validation set\n","\n","# Preprocess data (tokenization, padding)\n","def preprocess_function(examples):\n","  return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], padding=\"max_length\", truncation=True)\n","\n","train_data = train_data.map(preprocess_function, batched=True)\n","dev_data = dev_data.map(preprocess_function, batched=True)\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    per_device_train_batch_size=4,  # Adjust batch size based on your GPU memory\n","    learning_rate=2e-5,\n","    num_train_epochs=3,  \n","    logging_dir='./logs',\n","    report_to=\"none\",  \n","    save_strategy=\"no\",  \n",")\n","\n","\n","# Define metrics function\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    return {\"accuracy\": (preds == labels).mean()}\n","\n","# Define Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=dev_data,\n","    data_collator=default_data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Enable quantization\n","trainer.quantized_training = True\n","\n","# Train the model\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["results = trainer.evaluate()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T16:41:57.077133Z","iopub.status.busy":"2024-05-24T16:41:57.076616Z","iopub.status.idle":"2024-05-24T16:41:57.083518Z","shell.execute_reply":"2024-05-24T16:41:57.082488Z","shell.execute_reply.started":"2024-05-24T16:41:57.077092Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation Results:\n","eval_loss: 0.7565864324569702\n","eval_accuracy: 0.8645950076413652\n","eval_runtime: 554.7175\n","eval_samples_per_second: 17.694\n","eval_steps_per_second: 1.107\n","epoch: 3.0\n"]}],"source":["\n","# Print the evaluation metrics\n","print(\"Evaluation Results:\")\n","for key, value in results.items():\n","  print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T16:44:14.805991Z","iopub.status.busy":"2024-05-24T16:44:14.805093Z","iopub.status.idle":"2024-05-24T16:44:14.813041Z","shell.execute_reply":"2024-05-24T16:44:14.812095Z","shell.execute_reply.started":"2024-05-24T16:44:14.805957Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of trainable parameters: 355362819\n"]}],"source":["modelnum_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(\"Number of trainable parameters:\", modelnum_params)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T16:53:03.576848Z","iopub.status.busy":"2024-05-24T16:53:03.575922Z","iopub.status.idle":"2024-05-24T16:53:29.296919Z","shell.execute_reply":"2024-05-24T16:53:29.295714Z","shell.execute_reply.started":"2024-05-24T16:53:03.576792Z"},"trusted":true},"outputs":[],"source":["!pip install transformers==4.33.1 peft==0.11.1 datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T16:54:22.543765Z","iopub.status.busy":"2024-05-24T16:54:22.542931Z","iopub.status.idle":"2024-05-24T18:49:37.173958Z","shell.execute_reply":"2024-05-24T18:49:37.173133Z","shell.execute_reply.started":"2024-05-24T16:54:22.543727Z"},"trusted":true},"outputs":[],"source":["from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","from datasets import load_dataset\n","from transformers import TrainingArguments, Trainer, default_data_collator\n","from peft import LoraConfig, get_peft_model\n","\n","# Load tokenizer and model\n","model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\", num_labels=3)  # 3 for entailment, neutral, contradiction\n","\n","\n","# Configure LoRA\n","lora_config = LoraConfig(\n","    lora_alpha=16,\n","    lora_dropout=0.1,  \n","    r=8,  \n","    task_type=\"SEQ_CLS\",  \n","    target_modules=[\"query\", \"key\", \"value\", \"dense\"]  \n",")\n","\n","# Apply LoRA to the model\n","model = get_peft_model(model, lora_config)\n","\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    per_device_train_batch_size=4,  \n","    learning_rate=2e-5,\n","    num_train_epochs=3, \n","    logging_dir='./logs',\n","    report_to=\"none\",  \n","    save_strategy=\"no\",  \n",")\n","\n","# Define metrics function\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    return {\"accuracy\": (preds == labels).mean()}\n","\n","modelnum_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(\"Number of trainable parameters:\", modelnum_params)\n","\n","# Define Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=dev_data,\n","    data_collator=default_data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","\n","\n","# Train the model\n","trainer.train()\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T19:06:56.095547Z","iopub.status.busy":"2024-05-24T19:06:56.095187Z","iopub.status.idle":"2024-05-24T19:17:50.957520Z","shell.execute_reply":"2024-05-24T19:17:50.956532Z","shell.execute_reply.started":"2024-05-24T19:06:56.095520Z"},"trusted":true},"outputs":[],"source":["results = trainer.evaluate()\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T19:17:50.960091Z","iopub.status.busy":"2024-05-24T19:17:50.959307Z","iopub.status.idle":"2024-05-24T19:17:50.965429Z","shell.execute_reply":"2024-05-24T19:17:50.964435Z","shell.execute_reply.started":"2024-05-24T19:17:50.960055Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation Results:\n","eval_loss: 0.4594654440879822\n","eval_accuracy: 0.8445236882322975\n","eval_runtime: 654.8536\n","eval_samples_per_second: 14.988\n","eval_steps_per_second: 0.938\n","epoch: 3.0\n"]}],"source":["# Print the evaluation metrics\n","print(\"Evaluation Results:\")\n","for key, value in results.items():\n","  print(f\"{key}: {value}\")"]},{"cell_type":"markdown","metadata":{},"source":["### 3"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git\n","!pip install -q trl xformers wandb datasets einops gradio sentencepiece bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install transformers==4.33.1 peft==0.11.1 datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer, default_data_collator\n","from datasets import load_dataset\n","from peft import PeftModel, PromptTuningConfig, get_peft_model\n","\n","# Load tokenizer and model\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")\n","model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\", num_labels=3)  # 3 for entailment, neutral, contradiction\n","\n","\n","train_data = load_dataset(\"glue\", name=\"mnli\", split=\"train\")\n","\n","train_data = train_data.select(range(len(train_data) // 30))  # Select first 3% of the data\n","\n","dev_data = load_dataset(\"glue\", name=\"mnli\", split=\"validation_matched\")  # Use matched validation set\n","\n","def preprocess_function(examples):\n","    return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], padding=\"max_length\", truncation=True,max_length=128)\n","\n","train_data = train_data.map(preprocess_function, batched=True)\n","dev_data = dev_data.map(preprocess_function, batched=True)\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    per_device_train_batch_size=4,  \n","    learning_rate=2e-5,\n","    num_train_epochs=3,  \n","    logging_dir='./logs',\n","    report_to=\"none\",  \n","    save_strategy=\"no\", \n",")\n","\n","# Define metrics function\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    return {\"accuracy\": (preds == labels).mean()}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from peft import PromptEncoderConfig\n","model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\", num_labels=3)\n","\n","peft_config = PromptEncoderConfig(\n","    task_type=\"SEQ_CLS\",\n","    num_virtual_tokens=20,\n","    encoder_hidden_size=128\n",")\n","model = get_peft_model(model, peft_config)"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T21:29:54.635740Z","iopub.status.busy":"2024-05-28T21:29:54.635380Z","iopub.status.idle":"2024-05-28T21:29:54.643390Z","shell.execute_reply":"2024-05-28T21:29:54.642361Z","shell.execute_reply.started":"2024-05-28T21:29:54.635709Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of trainable parameters: 1352963\n"]}],"source":["modelnum_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(\"Number of trainable parameters:\", modelnum_params)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T21:29:56.497194Z","iopub.status.busy":"2024-05-28T21:29:56.496404Z","iopub.status.idle":"2024-05-28T22:15:54.278915Z","shell.execute_reply":"2024-05-28T22:15:54.277960Z","shell.execute_reply.started":"2024-05-28T21:29:56.497161Z"},"trusted":true},"outputs":[],"source":["from transformers import DataCollatorWithPadding\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    per_device_train_batch_size=4,  \n","    learning_rate=2e-5,\n","    num_train_epochs=3,  \n","    logging_dir='./logs',\n","    report_to=\"none\",  \n","    save_strategy=\"no\",  \n",")\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=dev_data,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n","\n","\n","trainer.train()\n","\n"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T22:21:12.278509Z","iopub.status.busy":"2024-05-28T22:21:12.278078Z","iopub.status.idle":"2024-05-28T22:24:52.087132Z","shell.execute_reply":"2024-05-28T22:24:52.086304Z","shell.execute_reply.started":"2024-05-28T22:21:12.278477Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='614' max='614' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [614/614 03:39]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["results = trainer.evaluate()\n"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T22:25:40.640906Z","iopub.status.busy":"2024-05-28T22:25:40.640548Z","iopub.status.idle":"2024-05-28T22:25:40.646224Z","shell.execute_reply":"2024-05-28T22:25:40.645272Z","shell.execute_reply.started":"2024-05-28T22:25:40.640878Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation Results:\n","eval_loss: 1.0957759618759155\n","eval_accuracy: 0.3392766174223128\n","eval_runtime: 219.8003\n","eval_samples_per_second: 44.654\n","eval_steps_per_second: 2.793\n","epoch: 3.0\n"]}],"source":["# Print the evaluation metrics\n","print(\"Evaluation Results:\")\n","for key, value in results.items():\n","  print(f\"{key}: {value}\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
